This paper adapted the findings of Penicka et al. \cite{Penicka_2022} to a low-level neural network controller for time-optimal flight through a sequence of waypoints while utilizing deep reinforcement learning methods. The controller achieves 100\% success rate on our test environment. However, our approach could not outperform their result on the test environment. This is due to a missing path planing algorithm in this work as well as the low-level controller approach which is known to be suboptimal \cite{Controller_benchmarking}. Nonetheless, neural network low-level controllers might prove useful for more complicated air vehicles. Possible further research topics might be to extend the curriculum learning strategy to more phases in which the velocity is further increased slowly, retraining with domain randomization to achieve robustness to varying model parameters or using a physical model with latency.