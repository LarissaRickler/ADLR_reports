The approach we used consisted of 1) formulating a progress maximization along the trajectory while reaching the waypoints and 2) a curriculum training strategy to train a neural network policy using deep reinforcement learning. Furthermore, we initially reduced the problem setting to a 2D world with a different model, elektra VTOL3, before applying our findings in a 3D world and a quadrotor model. In the following, the policy architecture, reward function, learning strategy and training details that were used in order to train a minimum time flight policy is described. 

\subsection{Policy Architecture}
\label{subsec:policy_architeture}
\input{sections/subsections:methods/policy_architeture}

\subsection{Reward Function}
\label{subsec:reward_fun}
\input{sections/subsections:methods/reward_fun}

\subsection{Training Strategy} 
\label{subsec:training_strategy}
\input{sections/subsections:methods/training_strategy}

\subsection{Training Details} 
\label{subsec:training_details}
\input{sections/subsections:methods/training}